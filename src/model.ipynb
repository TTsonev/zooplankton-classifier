{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Dense, Flatten, Reshape, RandomFlip, RandomRotation, RandomZoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/zooplankton/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"Lucicutiidae\", \"Mecynocera\", \"Mysida\", \"Ostracoda\", \n",
    "        \"Pleuromamma\", \"Pontellidae\", \"Rhincalanidae\", \"Sapphirina\", \n",
    "        \"Scolecitrichidae\", \"Sergestidae\", \"Subeucalanidae\", \"Temoridae\", \n",
    "        \"Acartiidae\", \"Aetideidae\", \"Calocalanus\", \"Calyptopsis\", \n",
    "        \"Candaciidae\", \"Centropagidae\", \"Cladocera\", \"Copilia\", \n",
    "        \"Eucalanidae\", \"Euchaetidae\", \"Haloptilus\", \"Harpacticoida\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constuct training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20142 files belonging to 24 classes.\n",
      "Using 16114 files for training.\n",
      "Found 20142 files belonging to 24 classes.\n",
      "Using 4028 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 90\n",
    "img_width = 90\n",
    "img_channels = 3\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  seed=123,\n",
    "  subset=\"training\",\n",
    "  validation_split=0.2,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_dir,\n",
    "  seed=123,\n",
    "  subset=\"validation\",\n",
    "  validation_split=0.2,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate \"additional\" images by augmenting existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = Sequential([\n",
    "    RandomRotation(factor=0.2, input_shape=(img_height, img_width, img_channels)),\n",
    "    RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    RandomFlip(mode='horizontal')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    augmentation,\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, img_channels)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(CLASSES), activation='softmax')   # multiclass classification => softmax\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),     # SCCrossentrtopy loss for non-enocded, multiple classes\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_70 (Sequential)  (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 88, 88, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 44, 44, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 42, 42, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 10368)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               5308928   \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,414,744\n",
      "Trainable params: 5,414,616\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Callback (stops training if no progress is being made and loads best epoch weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class zooplankton_callback(keras.callbacks.Callback):\n",
    "    def __init__ (self, model, epochs):\n",
    "        super(zooplankton_callback, self).__init__()\n",
    "        self.model=model               \n",
    "        self.epochs=epochs\n",
    "        self.lowest_vloss=np.inf\n",
    "        self.best_weights=self.model.get_weights()\n",
    "        self.best_epoch=1\n",
    "                \n",
    "    def on_train_end(self, logs=None):  \n",
    "        self.model.set_weights(self.best_weights) \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):  \n",
    "        v_loss=logs.get('val_loss')  \n",
    "        if v_loss< self.lowest_vloss:\n",
    "            self.lowest_vloss=v_loss\n",
    "            self.best_weights=self.model.get_weights() \n",
    "            self.best_epoch=epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "callbacks=[zooplankton_callback(model, epochs)]\n",
    "\n",
    "model.fit(x=train_ds,  \n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            callbacks=callbacks,  \n",
    "            validation_data=val_ds,\n",
    "            validation_steps=None,\n",
    "            shuffle=False,  \n",
    "            initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2507 files belonging to 24 classes.\n",
      "Using 2006 files for training.\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/home/ttsonev/Desktop/Projects/zooplankton-files/zooplankton/test'\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  seed=123,\n",
    "  subset=\"training\",\n",
    "  validation_split=0.2,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "model.save(\"model\", options=io_option)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zooplankton",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
